			+--------------------+
			|       CS 124       |
			| PROJECT 3: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Tim Menninger <tmenninger@caltech.edu>
Jerry Zhang <jerry.zhang@caltech.edu>
Jack Wang <j.wang@caltech.edu>

>> Specify how many late tokens you are using on this assignment: 0

>> What is the Git repository and commit hash for your submission?
   (You only need to include the commit-hash in the file you submit
   on Moodle.)

   Repository URL: /cs/courses/cs124/pintos-cit.git 
   commit ...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

			      THREADS
			      =======

---- LOGISTICS ----

These questions will help us to keep track of the difficulty level of
assignments, as well as keeping track of which team members worked on
which parts.

>> L1: How many hours did each team member spend on this assignment?
   Make sure that each member's total time is listed.
   
   Tim 16 hours
   Jerry 9 hours
   Jack 8 hours

>> L2: What did each team member focus on for this assignment?  Keep
   descriptions to 25-30 words or less.
   
   Tim - Priority donations
   Jerry - Alarm and fixed-point library
   Jack - Advanced scheduling


			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
Added int64_t wake_time; to struct thread.
This variable keeps track of the time that a sleeping thread will be 
awoken. The thread is blocked until that time comes. If a thread is
not sleeping, the value is -1.

Added struct list sleeping_list to global variables.
This list keeps track of which threads are currently asleep. It uses the
same elem as ready_list so it needs no extra memory.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Interrupts are disabled, the time the thread will wake is recorded in
the thread struct, the thread adds itself to sleeping_list, 
and the thread blocks. Every timer interrupt, sleeping threads
are checked to see if that time has passed, and if so, the thread 
is unblocked.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
A list of sleeping threads is kept so only the sleeping threads
have to be checked for waking, rather than all threads or all
blocked threads. 
The next step would be to binary search insert each
thread into sleeping_list based on wake_time so the list is sorted
, and have the loop stop as soon as it reaches a thread with a 
higher wake_time than the cur_time. This way minimal time is wasted on 
threads that aren't waking up. I didn't implement this because list.h
didn't already include a binary insert.



---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
Interrupts are turned off in timer_sleep()

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
Interrupts are turned off

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
This is superior to not having sleeping_list and just iterating through
all_list since no time is wasted on threads that are not sleeping.


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:
	struct list priority_donations;
    struct list_elem priority_elem;
    int orig_priority;
	struct lock *lock_needed;
	
	-priority_donations is a list of priority_elems that have been donated
	to this thread.
	-priority_elem is the list_element that a thread can donate to another
	lower priority thread
	-orig_priority is the priority of the thread if nothing has been donated
	to it
	-lock_needed is a pointer to the resource the thread donated its priority
	to get, NULL if none.
	
Added global variable:
	bool thread_waiting;
	
	-thread_waiting is a flag that indicates a ready thread has higher priority
	than the running thread.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

When thread A needs resource R, which is owned by lower priority thread B, A
keeps a pointer to resource R and then adds its priority_elem to B's
priority_donations list, updating B's running priority.  When B lets go of
resource R, it is realized that A is waiting on R because it is in the waiting
list and A's lock_needed points to R.  Thus, we know that B has a priority_elem
from A to remove from priority_donations.  This happens and B's priority is set
to either the max priority donation remaining or its orig_priority.  A's
lock_needed goes to NULL and A is allowed to proceed.  If it turned out that
B could not run because resource S was needed but owned by lower priority
thread C, then when donating to B, B would realize it has a lock_needed and
donate its priority to the holder of lock_needed.  The releasing of the
resource and resetting of priority works exactly the same whether it is a
nested priority donation or not.

Refer to the ASCII art diagram for the situation in which thread priority from
high to low is A B C D.  Each column is another step in the process.  Thread
row is the priority of the thread.  X means the thread is not ready, whether
that means it is blocked or not running or dead.

1: Currently, C is blocked by D
2: B needs something owned by C, so it gives its priority to C which gives
that priority to D
3: D finishes with C but still needs to run with B
4: A becomes ready, has higher priority than B
5: A finishes, thread D still runs with B
6: D finishes with B, B can run.  C still not highest priority
7: A needs resource from C. C gets A's priority and runs
8: C finishes.  A finishes.  B can run. D now ready but lower priority
9: B finishes, D can run
10: D finishes

            1    2    3    4    5    6    7    8    9    10
-------------------------------------------------------------------------------
Thread A    [X]  [X]  [X]  [A]  [X]  [X]  [X]  [X]  [X]  [X]
-------------------------------------------------------------------------------
Donations


-------------------------------------------------------------------------------
Thread B    [X]  [X]  [X]  [X]  [X]  [B]  [B]  [B]  [X]  [X]
-------------------------------------------------------------------------------
Donations


-------------------------------------------------------------------------------
Thread C    [X]  [X]  [C]  [C]  [C]  [C]  [A]  [X]  [X]  [X]
-------------------------------------------------------------------------------
Donations        B                        A


-------------------------------------------------------------------------------
Thread D    [C]  [B]  [B]  [B]  [B]  [X]  [X]  [D]  [D]  [X]
-------------------------------------------------------------------------------
Donations   C    B,C  B    B    B


-------------------------------------------------------------------------------

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We iterate through the waiting threads for each and wake up the one with the
highest priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

lock_acquire() is called.  It is seen that the holder has lower priority so
the current thread donates its priority to the thread that holds the lock by
adding its priority_elem to the priority_donations list and changing its
priority.  It then keeps a pointer in the caller's lock_needed attribute.
If this thread is also waiting on a lock, then its lock_needed variable will
not be NULL, so this priority will trickle to the holder of that lock_needed,
which will do the same check and so on until lock_needed is NULL.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

lock_release() is called.  If the lock holder has priority donations, then
we iterate through them to see if any of those donations are from threads
waiting on this lock.  If so, then we can unblock that thread.  Meanwhile, the
holder's priority is set to orig_priority or the highest still-donated 
priority.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

In set_priority, we could be making the priority less than the next highest
donation that it has.  If we were to change the priority right away, this
would cause the thread to ignore the priority donation.  We handle this by
changing the orig_priority to the new_priority, and only changing the
running priority if it has no donations or is higher than the current
priority.

This cannot use a lock because set_priority may be called in an interrupt
handler, and interrupt handlers cannot obtain locks.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.c we added :
	fixed_point load_avg;
	fixed_point load_coefficient;

These are to keep track of the load avg in the BSD scheduling update of recent
cpu that happens every 4 ticks. load_coffecient = 2 * load_avg / (2 * load_avg
+ 1), just to not recalculate for every thread.


In the thread struct defined in thread.h we add the fields:
	int nice;
	fixed_point recent_cpu;
to keep track of the niceness and recent cpu use of each thread.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0		0	0	0	63	61	59		A
 4		4	0	0	62	61	59		A
 8		8	0	0	61	61	59		B
12      8	4	0	61	60	59		A
16		12	4	0	60	60	59		B
20		12	8	0	60	59	59		A
24		16	8	0	59	59	59		C
28		16	8	4	59	59	58		B
32		16	12	4	59	58	58		A
36		20	12	4	58	58	58		C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

There's ambiguity when there are multiple threads of highest priority. In
such a case, the specification only says to follow round robin order. This
does not specify what that order is, only that all those threads will each get
a turn to run. The order we chose for the round robin order is least recently
run thread will run first in case of multiple competing threads. Our scheduler
follows this ordering. 

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

How much work gets done inside the interrupt affects how much a thread gets to
run per tick. The more work the interrupt handler does, the less the thread
gets to run. Thus, the thread takes more ticks to complete its task. 
Thus, doing more work than what is necessary inside the interrupt handler
negatively impacts performance.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Our design uses a single queue rather than one queue per priority level. This
has the advantage of being much simpler to implement. In implementing it, we 
used the existing priority scheduling and just updated the priority each every
4 ticks instead of it being static. There is less logic and less to get wrong
than the multi queue appraoch. However, this approach is also slower,
especially when there are a lot of threads to schedule. Having multiple queues
means that we wouldn't have to look through all the ready threads to find the 
next thread to run, where as in the single queue case we do. If we were to 
improve out desgin, we would implement the multiple queues.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We abstracted fixed point numbers as a typedef of int32_t and created
a set of functions to manipulate the values. This allowed us to focus 
on the problem rather than the details of how fixed point numbers work.
An inline function or macro would have been slightly more efficient, 
but the effect would not be very noticable.

			  SURVEY QUESTIONS
			  ================

Answering these questions is optional, but it will help us improve the
course in future years.  Feel free to tell us anything you want - these
questions are just to spur your thoughts.  Also, feel free to be completely
honest if there are issues with the assignment or the course - you won't be
penalized.  We can't fix things until we know about them.  :-)

>> In your opinion, was this assignment, or any of the parts of it, too
>> easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Were there any parts of the assignment that you felt were unnecessarily
>> tedious or pointless?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the instructor and/or TAs to more
>> effectively assist students, either for future quarters or the remaining
>> projects?

>> Any other comments?

